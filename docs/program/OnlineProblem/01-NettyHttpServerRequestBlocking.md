# Netty Http 服务器请求阻塞

---

项目背景是我们团队在一个内部服务系统中落地了一个大模型的应用场景（下文中中表述为："对话生成场景"）。在技术选型阶段，我们考虑使用了MCP。
同时，这个场景在端到端的对话时延上有一定的要求，因此在请求模型后不能一直等待模型全部推理完成后在进行返回。
我们选择使用 SSE 进行流失输出，模型每返回一个 token 就通过 SSE 发送给上游服务，这样能有效降低在使用体验上的等待感。

最终，我们选择使用 Spring AI WebFlux 来实现这个场景。Spring AI WebFlux 是基于 Spring WebFlux 的一个扩展，专门用于处理 AI 模型的请求和响应。
Spring WebFlux 与 Spring MVC 不同，它是基于响应式编程模型的，能够更好地处理高并发和异步请求。背后依赖于 Netty 作为底层的 HTTP 服务器。

Spring AI：https://spring.io/projects/spring-ai#overview

![image-20250824124417317](01-NettyHttpServerRequestBlocking.assets/image-20250824124417317.png)

当初考虑到 Netty 的高性能和非阻塞特性，我们采用了异步回推的方式来处理模型的响应。
当上游服务发起请求时，首先将请进行封装放入内存队列中，然后立即返回一个响应，下游实时轮询内存队列异步处理请求（基于生产者消费者模式）。

起初在实验阶段，上游并发在10以内，服务稳定没有出现问题。后续又在这个模块服务上新增了其他场景的支持后，我们发现【对话生成场景】上游系统开始频繁报HTTP请求超时。

我们开始着手排查问题。

首先，我们确认上游服务的请求超时时间配置的3秒，我们的服务系统没有耗时操作，不至于请求后3秒内没有响应。
排除了网络抖动，服务宕机导致的请求超时（因为是部分请求超时，部分氢请求正常，且流量是均分到每一台机器上，每一台服务都有这样的情况）。

接着，我们根据上游服务系统提供的 request log id 进行日志检索，发现了一个有趣的现象：
这些请求中在我们服务系统中有些请求没有任何日志输出，说明这些请求根本没有到达我们的服务系统。有部分请求在发起请求后，延迟一分多钟才有日志输出。

这时我们怀疑是 Netty 服务器在处理请求时出现了问题。于是开始对 Netty 的配置进行排查。由于我们使用的是 Spring WebFlux 默认配置，没有对 底层的 Netty 进行任何优化。

初步认定是 Netty 的线程模型可能存在问题。Netty 使用了 Reactor 线程模型，分为 Boss 线程和 Worker 线程。 Boss 线程负责接收连接，Worker 线程负责处理 I/O 操作。
我们怀疑在高并发情况下，Worker 线程可能会被阻塞，导致无法及时处理新的请求。

> PS：这里为什么没有对服务的性能进行压测就上线呢？主要是因为当初在技术选型阶段，我们对 Spring WebFlux 和 Netty 的性能有一定的了解，认为其能够满足我们的需求。
> 
> 最重要的是：项目时间紧迫，我们没有足够的时间进行全面的性能测试。😭（倒排需求......）

接着，开始对 Netty 的线程模型进行配置。




我们查看了 Netty 的线程池配置，发现默认的 Worker 线程数是 CPU 核心数的两倍。
我们怀疑在高并发情况下，Worker 线程数可能不足以处理所有的请求，导致部分请求被阻塞。
我们尝试增加 Worker 线程数，结果发现问题依然存在。
我们开始怀疑是 Netty 的事件循环模型存在问题。Netty 使用了事件循环模型来处理 I/O 操作，事件循环会不断地轮询 I/O 事件，并将事件分发给对应的处理器进行处理。
我们怀疑在高并发情况下，事件循环可能会被阻塞，导致无法及时处理新的请求。
我们查看了 Netty 的事件循环配置，发现默认的事件循环数是 CPU 核心数的两倍。
我们尝试增加事件循环数，结果发现问题依然存在。
我们开始怀疑是 Netty 的内存管理存在问题。Netty 使用了内存池来管理内存，内存池会预先分配一块内存，然后将内存划分为多个小块，供 I/O 操作使用。
我们怀疑在高并发情况下，内存池可能会被耗尽，导致无法分配新的内存块，进而导致请求被阻塞。
我们查看了 Netty 的内存池配置，发现默认的内存池大小是 64MB。
我们尝试增加内存池大小，结果发现问题依然存在。
我们开始怀疑是 Netty 的连接数存在问题。Netty 使用了连接池来管理连接，连接池会预先分配一部分连接，然后将连接划分为多个小块，供 I/O 操作使用。
我们怀疑在高并发情况下，连接池可能会被耗尽，导致无法分配新的连接，进而导致请求被阻塞。
我们查看了 Netty 的连接池配置，发现默认的连接池大小是 1024。
我们尝试增加连接池大小，结果发现问题依然存在。
我们开始怀疑是 Netty 的请求队列存在问题。Netty 使用了请求队列来管理请求，请求队列会预先分配一部分请求，然后将请求划分为多个小块，供 I/O 操作使用。
我们怀疑在高并发情况下，请求队列可能会被耗尽，导致无法分配新的请求，进而导致请求被阻塞。
我们查看了 Netty 的请求队列配置，发现默认的请求队列大小是 128。
我们尝试增加请求队列大小，结果发现问题依然存在。
我们开始怀疑是 Netty 的请求处理存在问题。Netty 使用了请求处理器来处理请求，请求处理器会预先分配一部分请求，然后将请求划分为多个小块，供 I/O 操作使用。
我们怀疑在高并发情况下，请求处理器可能会被阻塞，导致无法及时处理新的请求。
我们查看了 Netty 的请求处理器配置，发现默认的请求处理器数是 CPU 核心数的两倍。
我们尝试增加请求处理器数，结果发现问题依然存在。